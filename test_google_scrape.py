import requests
import time
import sys
import json

# Configuration
BASE_URL = "http://localhost:24006"  # API base URL
SEARCH_TERM = "trump"
AI_PROVIDER = "anthropic"  # Or "openai", "google" etc. if configured
POLL_INTERVAL_SECONDS = 5
MAX_POLL_ATTEMPTS = 60 # Poll for up to 5 minutes

TASK_INSTRUCTION = (
    f"Go to google.com, search for '{SEARCH_TERM}'. "
    "Identify the first organic search result link (ignoring ads, news boxes, etc.). "
    "Click on that link. Wait for the linked page to fully load. "
    "Return the full text content of that final loaded page."
)

def run_scrape_task():
    """Runs the Google scrape task via the API and prints results."""
    task_id = None
    print(f"Starting task with instruction: '{TASK_INSTRUCTION}' using provider '{AI_PROVIDER}'...")

    # 1. Start the task
    try:
        start_response = requests.post(
            f"{BASE_URL}/api/v1/run-task",
            json={
                "task": TASK_INSTRUCTION,
                "ai_provider": AI_PROVIDER
            },
            timeout=30 # Add a timeout for the request itself
        )
        start_response.raise_for_status() # Raise an exception for bad status codes (4xx or 5xx)
        task_info = start_response.json()
        task_id = task_info.get("id")
        if not task_id:
            print("Error: Failed to get task ID from response.")
            print("Response:", task_info)
            return False
        print(f"Task started successfully. Task ID: {task_id}")
        print(f"Live view: {BASE_URL}{task_info.get('live_url', '')}")

    except requests.exceptions.RequestException as e:
        print(f"Error starting task: {e}")
        return False

    # 2. Poll for status
    print("Polling for task completion...")
    for attempt in range(MAX_POLL_ATTEMPTS):
        try:
            status_response = requests.get(f"{BASE_URL}/api/v1/task/{task_id}/status", timeout=10)
            status_response.raise_for_status()
            status_data = status_response.json()
            current_status = status_data.get("status")
            print(f"Attempt {attempt + 1}/{MAX_POLL_ATTEMPTS}: Status = {current_status}")

            if current_status in ["finished", "failed", "stopped"]:
                print("Task reached terminal state.")
                break # Exit polling loop

            time.sleep(POLL_INTERVAL_SECONDS)

        except requests.exceptions.RequestException as e:
            print(f"Error polling status (attempt {attempt + 1}): {e}")
            # Continue polling despite error for a few attempts
            if attempt > 5: # Give up after several polling errors
                 print("Aborting polling due to repeated errors.")
                 return False
            time.sleep(POLL_INTERVAL_SECONDS * 2) # Wait longer after an error

    else: # If loop finishes without break
        print(f"Task did not complete within {MAX_POLL_ATTEMPTS * POLL_INTERVAL_SECONDS} seconds.")
        return False

    # 3. Get final details
    print("\nFetching final task details...")
    try:
        final_response = requests.get(f"{BASE_URL}/api/v1/task/{task_id}", timeout=30)
        final_response.raise_for_status()
        final_data = final_response.json()

        print("\n--- Final Task Details ---")
        # Pretty print the JSON details
        print(json.dumps(final_data, indent=2))
        print("--- End Task Details ---")

        if final_data.get("status") == "finished":
             print("\nTask completed successfully!")
             if final_data.get("output"):
                  print("\nScraped Content Preview (first 500 chars):")
                  print(final_data["output"][:500] + "...")
             else:
                  print("\nNote: Task finished but no text output was returned.")
             return True
        else:
             print(f"\nTask ended with status: {final_data.get('status')}")
             if final_data.get("error"):
                  print(f"Error: {final_data['error']}")
             return False

    except requests.exceptions.RequestException as e:
        print(f"Error fetching final task details: {e}")
        return False

if __name__ == "__main__":
    success = run_scrape_task()
    print("\n-------------------------------------")
    print("REMINDER: Check the './data' directory on your host machine for potential screenshots or detailed logs generated by the underlying browser-use library.")
    print("-------------------------------------")
    sys.exit(0 if success else 1)
